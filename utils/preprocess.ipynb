{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4454d1ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "695b3787",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "train_data = pd.read_csv('../data/train.csv')\n",
    "test_data = pd.read_csv('../data/test.csv')\n",
    "test_labels = pd.read_csv('../data/test_labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1a17b8c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total train samples: 159571\n",
      "Total test samples: 153164\n",
      "Total test labels: 153164\n"
     ]
    }
   ],
   "source": [
    "# data size\n",
    "print(f\"Total train samples: {len(train_data)}\")\n",
    "print(f\"Total test samples: {len(test_data)}\")\n",
    "print(f\"Total test labels: {len(test_labels)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a0dcdd75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================== First rows ========================================\n",
      "First row of train data: \n",
      "                 id                                       comment_text  toxic  \\\n",
      "0  0000997932d777bf  Explanation\\nWhy the edits made under my usern...      0   \n",
      "\n",
      "   severe_toxic  obscene  threat  insult  identity_hate  \n",
      "0             0        0       0       0              0  \n",
      "\n",
      "First row of test data: \n",
      "                 id                                       comment_text\n",
      "0  00001cee341fdb12  Yo bitch Ja Rule is more succesful then you'll...\n",
      "\n",
      "First row of test labels: \n",
      "                 id  toxic  severe_toxic  obscene  threat  insult  \\\n",
      "0  00001cee341fdb12     -1            -1       -1      -1      -1   \n",
      "\n",
      "   identity_hate  \n",
      "0             -1  \n",
      "======================================== Column names ========================================\n",
      "Train data column names: \n",
      "Index(['id', 'comment_text', 'toxic', 'severe_toxic', 'obscene', 'threat',\n",
      "       'insult', 'identity_hate'],\n",
      "      dtype='object')\n",
      "\n",
      "Test data column names: \n",
      "Index(['id', 'comment_text'], dtype='object')\n",
      "\n",
      "Test labels column names: \n",
      "Index(['id', 'toxic', 'severe_toxic', 'obscene', 'threat', 'insult',\n",
      "       'identity_hate'],\n",
      "      dtype='object')\n",
      "train data:\n",
      "id               0\n",
      "comment_text     0\n",
      "toxic            0\n",
      "severe_toxic     0\n",
      "obscene          0\n",
      "threat           0\n",
      "insult           0\n",
      "identity_hate    0\n",
      "dtype: int64\n",
      "\n",
      "test data:\n",
      "id              0\n",
      "comment_text    0\n",
      "dtype: int64\n",
      "\n",
      "test labels:\n",
      "id               0\n",
      "toxic            0\n",
      "severe_toxic     0\n",
      "obscene          0\n",
      "threat           0\n",
      "insult           0\n",
      "identity_hate    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# first rows\n",
    "print(f\"=\"*40 + \" First rows \" + \"=\"*40)\n",
    "print(f\"First row of train data: \\n{train_data.head(1)}\")\n",
    "print()\n",
    "print(f\"First row of test data: \\n{test_data.head(1)}\")\n",
    "print()\n",
    "print(f\"First row of test labels: \\n{test_labels.head(1)}\")\n",
    "\n",
    "# column names\n",
    "print(f\"=\"*40 + \" Column names \" + \"=\"*40)\n",
    "print(f\"Train data column names: \\n{train_data.columns}\")\n",
    "print()\n",
    "print(f\"Test data column names: \\n{test_data.columns}\")\n",
    "print()\n",
    "print(f\"Test labels column names: \\n{test_labels.columns}\")\n",
    "\n",
    "# missing values per column per dataset\n",
    "print(\"train data:\")\n",
    "print(train_data.isnull().sum())\n",
    "print()\n",
    "print(\"test data:\")\n",
    "print(test_data.isnull().sum())\n",
    "print()\n",
    "print(\"test labels:\")\n",
    "print(test_labels.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "37a15bf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total test samples: 153164\n",
      "Total test samples with no -1's: 63978\n",
      "Total test samples with -1's: 89186\n"
     ]
    }
   ],
   "source": [
    "# for testing data, check how many rows have -1 values\n",
    "label_cols = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
    "\n",
    "no_neg_1 = test_labels[~(test_labels[label_cols] == -1).any(axis=1)]\n",
    "\n",
    "print(f\"Total test samples: {len(test_labels)}\")\n",
    "print(f\"Total test samples with no -1's: {len(no_neg_1)}\")\n",
    "print(f\"Total test samples with -1's: {len(test_labels) - len(no_neg_1)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0fa98b20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created test_1.csv with 63,978 samples\n",
      "First few rows:\n",
      "                 id                                       comment_text  toxic  \\\n",
      "0  0001ea8717f6de06  Thank you for understanding. I think very high...      0   \n",
      "1  000247e83dcc1211                   :Dear god this site is horrible.      0   \n",
      "2  0002f87b16116a7f  \"::: Somebody will invariably try to add Relig...      0   \n",
      "3  0003e1cccfd5a40a  \" \\n\\n It says it right there that it IS a typ...      0   \n",
      "4  00059ace3e3e9a53  \" \\n\\n == Before adding a new product to the l...      0   \n",
      "\n",
      "   severe_toxic  obscene  threat  insult  identity_hate  \n",
      "0             0        0       0       0              0  \n",
      "1             0        0       0       0              0  \n",
      "2             0        0       0       0              0  \n",
      "3             0        0       0       0              0  \n",
      "4             0        0       0       0              0  \n"
     ]
    }
   ],
   "source": [
    "# Create processed test data with no -1 labels\n",
    "test_1 = pd.merge(no_neg_1, test_data, on='id', how='inner')\n",
    "\n",
    "# Reorder columns to match train data\n",
    "column_order = ['id', 'comment_text'] + label_cols\n",
    "test_1 = test_1[column_order]\n",
    "\n",
    "# Save to test_1.csv\n",
    "test_1.to_csv('../data/test_1.csv', index=False)\n",
    "\n",
    "print(f\"Created test_1.csv with {len(test_1):,} samples\")\n",
    "print(f\"First few rows:\")\n",
    "print(test_1.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae8e98b3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
